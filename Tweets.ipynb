{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy files to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -copyFromLocal tweets.json tweets.json\n",
    "!hdfs dfs -copyFromLocal tweets.json.gz tweets.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converstion from JSON to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.read.json(\"tweets.json\")\n",
    "df.write.parquet(\"tweets.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7 M    .sparkStaging\r\n",
      "74.8 K   input\r\n",
      "185.9 M  server.log\r\n",
      "449.0 M  tweets.json\r\n",
      "63.3 M   tweets.json.gz\r\n",
      "59.4 M   tweets.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -du -h #The size of the parquet is actually little less than that of gzip file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find #retweets among the total tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 ms, sys: 0 ns, total: 10 ms\n",
      "Wall time: 28.4 s\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 1.8 ms\n",
      "+-----+\n",
      "|  _c0|\n",
      "+-----+\n",
      "|47934|\n",
      "+-----+\n",
      "\n",
      "CPU times: user 0 ns, sys: 10 ms, total: 10 ms\n",
      "Wall time: 8.9 s\n"
     ]
    }
   ],
   "source": [
    "%time df_json = sqlContext.read.json(\"tweets.json\")\n",
    "%time df_json.registerTempTable(\"tweets_json\")\n",
    "%time sqlContext.sql(\"select count(id), count(retweeted_status.id) from tweets_json\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON with GZ compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 ms, sys: 0 ns, total: 20 ms\n",
      "Wall time: 31 s\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 339 µs\n",
      "+------+-----+\n",
      "|   _c0|  _c1|\n",
      "+------+-----+\n",
      "|139434|47934|\n",
      "+------+-----+\n",
      "\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 9.09 s\n"
     ]
    }
   ],
   "source": [
    "%time df_json_gz = sqlContext.read.json(\"tweets.json.gz\")\n",
    "%time df_json_gz.registerTempTable(\"tweets_json_gz\")\n",
    "%time sqlContext.sql(\"select count(id), count(retweeted_status.id) from tweets_json_gz\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 ms, sys: 0 ns, total: 10 ms\n",
      "Wall time: 293 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 1.94 ms\n",
      "+------+-----+\n",
      "|   _c0|  _c1|\n",
      "+------+-----+\n",
      "|139434|47934|\n",
      "+------+-----+\n",
      "\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 3.13 s\n"
     ]
    }
   ],
   "source": [
    "%time df_parquet = sqlContext.read.parquet(\"tweets.parquet\")\n",
    "%time df_parquet.registerTempTable(\"tweets_parquet\")\n",
    "%time sqlContext.sql(\"select count(id), count(retweeted_status.id) from tweets_parquet\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing specific members from the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Source and Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `tweets_filtered.json.gz': No such file or directory\n",
      "CPU times: user 10 ms, sys: 0 ns, total: 10 ms\n",
      "Wall time: 28.8 s\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 360 µs\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 26.9 ms\n",
      "CPU times: user 10 ms, sys: 0 ns, total: 10 ms\n",
      "Wall time: 26.4 s\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r tweets_filtered.json.gz \n",
    "%time df_json_gz = sqlContext.read.json(\"tweets.json.gz\")\n",
    "%time df_json_gz.registerTempTable(\"tweets_json_gz\")\n",
    "%time df_json_gz = sqlContext.sql(\"select * from tweets_json_gz where id!=459403052467113984\")\n",
    "%time df_json_gz.write.json(\"tweets_filtered.json.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parquet Source and Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `tweets_filtered.parquet': No such file or directory\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 179 ms\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 283 µs\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 47.9 ms\n",
      "CPU times: user 10 ms, sys: 0 ns, total: 10 ms\n",
      "Wall time: 49.2 s\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r tweets_filtered.parquet \n",
    "%time df_parquet = sqlContext.read.parquet(\"tweets.parquet\")\n",
    "%time df_parquet.registerTempTable(\"tweets_parquet\")\n",
    "%time df =  sqlContext.sql(\"select * from tweets_parquet where id!=459403052467113984\")\n",
    "%time df.write.parquet(\"tweets_filtered.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
